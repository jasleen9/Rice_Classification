# -*- coding: utf-8 -*-
"""rice_img2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VEEVb0DDs1kWQOaF5hXx4ZzkQ85Renke
"""
import ssl

# Set the path to the cacert.pem file
ssl._create_default_https_context = ssl._create_unverified_context


# Import necessary libraries
import tensorflow as tf
import os, glob
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import Callback, EarlyStopping
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from sklearn.metrics import classification_report


# Path to the dataset
file_path = 'data'
class_names = sorted(os.listdir(file_path))
class_names

filepaths = list(glob.glob(file_path + '/**/*.*'))

print(filepaths[0:2])

labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],filepaths))

#print(labels)

filepath = pd.Series(filepaths, name = 'Filepath').astype(str)
labels = pd.Series(labels, name = 'Label')
data = pd.concat([filepath, labels], axis=1)
data = data.sample(frac=1).reset_index(drop=True)


"""counts = data.Label.value_counts()
sns.barplot(x=counts.index, y=counts)
plt.xlabel('Type')
plt.xticks(rotation=90)"""

train, test = train_test_split(data, test_size = 0.25, random_state = 42)

"""fig , axes = plt.subplots(nrows = 5, ncols = 3, figsize=(10,8), subplot_kw = {'xticks':[], 'yticks':[]})
for i , ax in enumerate(axes.flat):
  ax.imshow(plt.imread(data.Filepath[i]))
  ax.set_title(data.Label[i])
plt.tight_layout()
plt.show()"""

train_datagen = ImageDataGenerator(preprocessing_function= preprocess_input)
test_datagen = ImageDataGenerator(preprocessing_function= preprocess_input)

train_gen = train_datagen.flow_from_dataframe(
    dataframe=train,
    x_col='Filepath',
    y_col='Label',
    target_size=(100, 100),
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42
)
valid_gen = train_datagen.flow_from_dataframe(
    dataframe=test,
    x_col='Filepath',
    y_col='Label',
    target_size=(100,100),
    class_mode='categorical',
    batch_size=32,
    shuffle=False,
    seed=42
)
test_gen = train_datagen.flow_from_dataframe(
    dataframe=test,
    x_col='Filepath',
    y_col='Label',
    target_size=(100,100),
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

# Assuming train_gen is your training data generator
class_indices = train_gen.class_indices
print(class_indices)


pretrained_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'

pretrained_model = ResNet50(
    input_shape = (100,100,3),
    include_top = False,
    weights = 'imagenet',
    pooling = 'avg'
    )

pretrained_model.trainable = False

inputs = pretrained_model.input

x = Dense(128, activation='relu')(pretrained_model.output)
x = Dense(128, activation='relu')(x)

outputs = Dense(5, activation='softmax')(x)

model = Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
    )

my_callbacks = [
    EarlyStopping(
        monitor='val_accuracy',
        min_delta=0,
        patience=2,
        mode='auto')
]

history = model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=10
)

model.save('rice_variety_classification_model3.h5')

# Correct plotting of accuracy vs loss function graphs
plt.figure(figsize=(14, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title("Model Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Model Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

results = model.evaluate(test_gen, verbose=0)
print("Test Loss: {:.5f}".format(results[0]))
print("Test Accuracy: {:.2f}".format(results[1] * 100))

pred = model.predict(test_gen)
pred = np.argmax(pred, axis=1)

labels = (train_gen.class_indices)
labels = dict((v, k) for k, v in labels.items())
predictions = [labels[k] for k in pred]

y_test = list(test.Label)

# Classification report
print(classification_report(y_test, predictions))

# Confusion matrix
cm = confusion_matrix(y_test, predictions, labels=list(class_names))
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Plot distribution of true labels vs. predicted labels
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.countplot(y_test, order=class_names)
plt.title('True Label Distribution')
plt.xticks(rotation=90)

plt.subplot(1, 2, 2)
sns.countplot(predictions, order=class_names)
plt.title('Predicted Label Distribution')
plt.xticks(rotation=90)

plt.tight_layout()
plt.show()